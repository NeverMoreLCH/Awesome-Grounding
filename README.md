# Awesome-Grounding
A reading list of papers about Visual Grounding.

<br></br>

## Table of Contents
  * [Image Visual Grounding Papers](#image-visual-grounding-papers)
     * [Datasets](#datasets)
     * [2021 Papers](#2021-papers)
     * [2020 Papers](#2020-papers)
     * [2019 Papers](#2019-papers)
     * [2018 Papers](#2018-papers)
     * [2017 Papers](#2017-papers)
     * [2016 Papers](#2016-papers)
     * [2015 Papers](#2015-papers)
     * [2014 Papers](#2014-papers)

  * [Temporal Video Grounding Papers](#temporal-video-grounding-papers)
     * [Datasets](#datasets-1)
     * [2021 Papers](#2021-papers-1)
     * [2020 Papers](#2020-papers-1)
     * [2019 Papers](#2019-papers-1)
     * [2018 Papers](#2018-papers-1)
     * [2017 Papers](#2017-papers-1)
     
  * [Video Visual Grounding Papers](#video-visual-grounding-papers)
     * [Datasets](#datasets-2)
     * [2021 Papers](#2021-papers-2)
     * [2020 Papers](#2020-papers-2)
     * [2019 Papers](#2019-papers-2)
     * [2018 Papers](#2018-papers-2)
     * [2017 Papers](#2017-papers-2)
     * [2016 Papers](#2016-papers-1)
     * [2015 Papers](#2015-papers-1)
     * [2014 Papers](#2014-papers-1)

<br></br>

## Image Visual Grounding Papers
### Datasets
1. **XXX** [2021][CVPR] .[[paper]()][[中文解读]()]

### 2021 Papers
1. [2021][CVPR] Bottom-Up Shift and Reasoning for Referring Image Segmentation.[[paper](https://openaccess.thecvf.com/content/CVPR2021/papers/Yang_Bottom-Up_Shift_and_Reasoning_for_Referring_Image_Segmentation_CVPR_2021_paper.pdf)][[中文解读]()]
2. [2021][CVPR] Room-and-Object Aware Knowledge Reasoning for Remote Embodied Referring Expression.[[paper](https://openaccess.thecvf.com/content/CVPR2021/papers/Gao_Room-and-Object_Aware_Knowledge_Reasoning_for_Remote_Embodied_Referring_Expression_CVPR_2021_paper.pdf)][[中文解读]()]
3. [2021][CVPR] Iterative Shrinking for Referring Expression Grounding Using Deep Reinforcement Learning.[[paper](https://openaccess.thecvf.com/content/CVPR2021/papers/Sun_Iterative_Shrinking_for_Referring_Expression_Grounding_Using_Deep_Reinforcement_Learning_CVPR_2021_paper.pdf)][[中文解读]()]
4. [2021][CVPR] Locate then Segment: A Strong Pipeline for Referring Image Segmentation.[[paper](https://openaccess.thecvf.com/content/CVPR2021/papers/Jing_Locate_Then_Segment_A_Strong_Pipeline_for_Referring_Image_Segmentation_CVPR_2021_paper.pdf)][[中文解读]()]
5. [2021][CVPR] Scene-Intuitive Agent for Remote Embodied Visual Grounding.[[paper](https://openaccess.thecvf.com/content/CVPR2021/papers/Lin_Scene-Intuitive_Agent_for_Remote_Embodied_Visual_Grounding_CVPR_2021_paper.pdf)][[中文解读]()]
6. [2021][CVPR] Look Before You Leap: Learning Landmark Features for One-Stage Visual Grounding.[[paper](https://openaccess.thecvf.com/content/CVPR2021/papers/Huang_Look_Before_You_Leap_Learning_Landmark_Features_for_One-Stage_Visual_CVPR_2021_paper.pdf)][[中文解读]()]
7. [2021][CVPR] Cyclic Co-Learning of Sounding Object Visual Grounding and Sound Separation.[[paper](https://openaccess.thecvf.com/content/CVPR2021/papers/Tian_Cyclic_Co-Learning_of_Sounding_Object_Visual_Grounding_and_Sound_Separation_CVPR_2021_paper.pdf)][[中文解读]()]
8. [2021][CVPR] Refer-it-in-RGBD: A Bottom-up Approach for 3D Visual Grounding in RGBD Images.[[paper](https://openaccess.thecvf.com/content/CVPR2021/papers/Liu_Refer-It-in-RGBD_A_Bottom-Up_Approach_for_3D_Visual_Grounding_in_RGBD_CVPR_2021_paper.pdf)][[中文解读]()]
9. [2021][CVPR] Improving Weakly Supervised Visual Grounding by Contrastive Knowledge Distillation.[[paper](https://openaccess.thecvf.com/content/CVPR2021/papers/Wang_Improving_Weakly_Supervised_Visual_Grounding_by_Contrastive_Knowledge_Distillation_CVPR_2021_paper.pdf)][[中文解读]()]
10. [2021][CVPR] Relation-aware Instance Refinement for Weakly Supervised Visual Grounding.[[paper](https://openaccess.thecvf.com/content/CVPR2021/papers/Liu_Relation-aware_Instance_Refinement_for_Weakly_Supervised_Visual_Grounding_CVPR_2021_paper.pdf)][[中文解读]()]
11. [2021][CVPR] Encoder Fusion Network with Co-Attention Embedding for Referring Image Segmentation.[[paper](https://openaccess.thecvf.com/content/CVPR2021/papers/Feng_Encoder_Fusion_Network_With_Co-Attention_Embedding_for_Referring_Image_Segmentation_CVPR_2021_paper.pdf)][[中文解读]()]
12. [2021][CVPR] .[[paper]()][[中文解读]()]


### 2020 Papers


### 2019 Papers


### 2018 Papers


### 2017 Papers


### 2016 Papers


### 2015 Papers


### 2014 Papers


<br></br>


## Temporal Video Grounding Papers
### Datasets
1. **Charades-STA** [2017][ICCV] TALL: Temporal Activity Localization via Language Query.[[paper](http://openaccess.thecvf.com/content_ICCV_2017/papers/Gao_TALL_Temporal_Activity_ICCV_2017_paper.pdf)][[dataset](https://github.com/jiyanggao/TALL)][[中文解读]()]
2. **ActivityNet Captions** [2017][ICCV] Dense-Captioning Events in Videos.[[paper](https://openaccess.thecvf.com/content_ICCV_2017/papers/Krishna_Dense-Captioning_Events_in_ICCV_2017_paper.pdf)][[dataset](https://cs.stanford.edu/people/ranjaykrishna/densevid/)][[中文解读]()]
3. **DiDeMo** [2017][ICCV] Localizing Moments in Video with Natural Language.[[paper](https://openaccess.thecvf.com/content_ICCV_2017/papers/Hendricks_Localizing_Moments_in_ICCV_2017_paper.pdf)][[dataset](https://github.com/LisaAnne/TemporalLanguageRelease)][[中文解读]()]

### 2021 Papers
1. [2021][ACL] Parallel Attention Network with Sequence Matching for Video Grounding.[[paper](https://arxiv.org/pdf/2105.08481)][[中文解读]()]
2. [2021][CVPR] Cascaded Prediction Network via Segment Tree for Temporal Video Grounding.[[paper](https://openaccess.thecvf.com/content/CVPR2021/papers/Zhao_Cascaded_Prediction_Network_via_Segment_Tree_for_Temporal_Video_Grounding_CVPR_2021_paper.pdf)][[中文解读]()]
3. [2021][CVPR] Context-aware Biaffine Localizing Network for Temporal Sentence Grounding.[[paper](https://openaccess.thecvf.com/content/CVPR2021/papers/Liu_Context-Aware_Biaffine_Localizing_Network_for_Temporal_Sentence_Grounding_CVPR_2021_paper.pdf)][[中文解读]()]
4. [2021][CVPR] Embracing Uncertainty: Decoupling and De-bias for Robust Temporal Grounding.[[paper](https://openaccess.thecvf.com/content/CVPR2021/papers/Zhou_Embracing_Uncertainty_Decoupling_and_De-Bias_for_Robust_Temporal_Grounding_CVPR_2021_paper.pdf)][[中文解读]()]
5. [2021][CVPR] Interventional Video Grounding with Dual Contrastive Learning.[[paper](https://openaccess.thecvf.com/content/CVPR2021/papers/Nan_Interventional_Video_Grounding_With_Dual_Contrastive_Learning_CVPR_2021_paper.pdf)][[中文解读]()]
6. [2021][TMM] Weakly Supervised Temporal Adjacent Network for Language Grounding.[[paper](https://arxiv.org/pdf/2106.16136)][[中文解读]()]
7. [2021][CVPR] Zero-shot Natural Language Video Localization.[[paper](https://openaccess.thecvf.com/content/ICCV2021/papers/Nam_Zero-Shot_Natural_Language_Video_Localization_ICCV_2021_paper.pdf)][[中文解读]()]
8. [2021][CVPR] .[[paper]()][[中文解读]()]

### 2020 Papers
1. [2020][AAAI] Weakly-Supervised Video Moment Retrieval via Semantic Completion Network.[[paper](https://ojs.aaai.org/index.php/AAAI/article/download/6820/6674)][[中文解读]()]
2. [2020][AAAI] Tree-Structured Policy based Progressive Reinforcement Learning for Temporally Language Grounding in Video.[[paper](https://ojs.aaai.org/index.php/AAAI/article/download/6924/6778)][[中文解读]()]
3. [2020][AAAI] Learning 2D Temporal Adjacent Networks for Moment Localization with Natural Language.[[paper](https://ojs.aaai.org/index.php/AAAI/article/view/6984/6838)][[中文解读]()]
4. [2020][ACMMM] Fine-grained Iterative Attention Network for Temporal Language Localization in Videos.[[paper](https://arxiv.org/pdf/2008.02448)][[中文解读]()]
5. [2020][ECCV] Learning Modality Interaction for Temporal Sentence Localization and Event Captioning in Videos.[[paper](https://arxiv.org/pdf/2007.14164)][[中文解读]()]
6. [2020][CVPR] Local-Global Video-Text Interactions for Temporal Grounding.[[paper](http://openaccess.thecvf.com/content_CVPR_2020/papers/Mun_Local-Global_Video-Text_Interactions_for_Temporal_Grounding_CVPR_2020_paper.pdf)][[中文解读]()]
7. [2020][CVPR] Dense Regression Network for Video Grounding.[[paper](https://openaccess.thecvf.com/content_CVPR_2020/papers/Zeng_Dense_Regression_Network_for_Video_Grounding_CVPR_2020_paper.pdf)][[中文解读]()]

### 2019 Papers
1. [2019][AAAI] Localizing Natural Language in Videos.[[paper](https://ojs.aaai.org/index.php/AAAI/article/view/4827/4700)][[中文解读]()]
2. [2019][AAAI] Multilevel Language and Vision Integration for Text-to-Clip Retrieval.[[paper](https://ojs.aaai.org/index.php/AAAI/article/view/4938/4811)][[中文解读]()]
3. [2019][AAAI] Read,Watch, and Move: Reinforcement Learning for Temporally Grounding Natural Language Descriptions in Videos.[[paper](https://ojs.aaai.org/index.php/AAAI/article/download/4854/4727)][[中文解读]()]
4. [2019][AAAI] Semantic Proposal for Activity Localization in Videos via Sentence Query.[[paper](https://ojs.aaai.org/index.php/AAAI/article/view/4830/4703)][[中文解读]()]
5. [2019][AAAI] To Find Where You Talk: Temporal Sentence Localization in Video with Attention Based Location Regression.[[paper](https://ojs.aaai.org/index.php/AAAI/article/download/4950/4823)][[中文解读]()]
6. [2019][CVPR] Language-driven Temporal Activity Localization: A Semantic Matching Reinforcement Learning Model.[[paper](http://openaccess.thecvf.com/content_CVPR_2019/papers/Wang_Language-Driven_Temporal_Activity_Localization_A_Semantic_Matching_Reinforcement_Learning_Model_CVPR_2019_paper.pdf)][[中文解读]()]
7. [2019][CVPR] MAN: Moment Alignment Network for Natural Language Moment Retrieval via Iterative Graph Adjustment.[[paper](http://openaccess.thecvf.com/content_CVPR_2019/papers/Zhang_MAN_Moment_Alignment_Network_for_Natural_Language_Moment_Retrieval_via_CVPR_2019_paper.pdf)][[中文解读]()]
8. [2019][CVPR] Weakly Supervised Video Moment Retrieval From Text Queries .[[paper]()][[中文解读](https://openaccess.thecvf.com/content_CVPR_2019/papers/Mithun_Weakly_Supervised_Video_Moment_Retrieval_From_Text_Queries_CVPR_2019_paper.pdf)]
9. [2019][EMNLP] WSLLN:Weakly Supervised Natural Language Localization Networks.[[paper](https://arxiv.org/pdf/1909.00239)][[中文解读]()]
10. [2019][NeurIPS] Semantic Conditioned Dynamic Modulation for Temporal Sentence Grounding in Videos.[[paper](http://papers.neurips.cc/paper/8344-semantic-conditioned-dynamic-modulation-for-temporal-sentence-grounding-in-videos.pdf)][[中文解读]()]
11. [2019][WACV] MAC: Mining Activity Concepts for Language-based Temporal Localization.[[paper](https://arxiv.org/pdf/1811.08925)][[中文解读]()]

### 2018 Papers
1. [2018][EMNLP] Localizing Moments in Video with Temporal Language.[[paper](https://arxiv.org/pdf/1809.01337)][[中文解读]()]
2. [2018][EMNLP] Temporally Grounding Natural Sentence in Video.[[paper](https://www.aclweb.org/anthology/D18-1015.pdf)][[中文解读]()]
3. [2018][SIGIR] Attentive Moment Retrieval in Videos.[[paper](https://www.researchgate.net/profile/Meng-Liu-67/publication/326141659_Attentive_Moment_Retrieval_in_Videos/links/6052a32f299bf173674e0c03/Attentive-Moment-Retrieval-in-Videos.pdf)][[中文解读]()]


### 2017 Papers
1. [2017][ICCV] TALL: Temporal Activity Localization via Language Query.[[paper](http://openaccess.thecvf.com/content_ICCV_2017/papers/Gao_TALL_Temporal_Activity_ICCV_2017_paper.pdf)][[中文解读]()]
2. [2017][ICCV] Dense-Captioning Events in Videos.[[paper](https://openaccess.thecvf.com/content_ICCV_2017/papers/Krishna_Dense-Captioning_Events_in_ICCV_2017_paper.pdf)][[中文解读]()]
3. [2017][ICCV] Localizing Moments in Video with Natural Language.[[paper](https://openaccess.thecvf.com/content_ICCV_2017/papers/Hendricks_Localizing_Moments_in_ICCV_2017_paper.pdf)][[中文解读]()]


<br></br>

## Video Visual Grounding Papers
### Datasets


### 2021 Papers
1. [2021][CVPR] Cascaded Prediction Network via Segment Tree for Temporal Video Grounding.[[paper](https://openaccess.thecvf.com/content/CVPR2021/papers/Zhao_Cascaded_Prediction_Network_via_Segment_Tree_for_Temporal_Video_Grounding_CVPR_2021_paper.pdf)][[中文解读]()]
2. [2021][CVPR] Context-aware Biaffine Localizing Network for Temporal Sentence Grounding.[[paper](https://openaccess.thecvf.com/content/CVPR2021/papers/Liu_Context-Aware_Biaffine_Localizing_Network_for_Temporal_Sentence_Grounding_CVPR_2021_paper.pdf)][[中文解读]()]
3. [2021][CVPR] Embracing Uncertainty: Decoupling and De-bias for Robust Temporal Grounding.[[paper](https://openaccess.thecvf.com/content/CVPR2021/papers/Zhou_Embracing_Uncertainty_Decoupling_and_De-Bias_for_Robust_Temporal_Grounding_CVPR_2021_paper.pdf)][[中文解读]()]
4. [2021][CVPR] Interventional Video Grounding with Dual Contrastive Learning.[[paper](https://openaccess.thecvf.com/content/CVPR2021/papers/Nan_Interventional_Video_Grounding_With_Dual_Contrastive_Learning_CVPR_2021_paper.pdf)][[中文解读]()]
5. [2021][CVPR] Co-Grounding Networks with Semantic Attention for Referring Expression Comprehension in Videos.[[paper](https://openaccess.thecvf.com/content/CVPR2021/papers/Song_Co-Grounding_Networks_With_Semantic_Attention_for_Referring_Expression_Comprehension_in_CVPR_2021_paper.pdf)][[中文解读]()]
6. [2021][CVPR] .[[paper]()][[中文解读]()]

### 2020 Papers


### 2019 Papers


### 2018 Papers


### 2017 Papers


### 2016 Papers


### 2015 Papers


### 2014 Papers

